---
title: 'Preprocessing Similarity Judgment Task'
author: "morgan moyer"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE, warning=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(lme4)
library(lmerTest)
library(multcomp) # not available for this version of R
library(stringr)
library(textstem)
library(tidyverse)
theme_set(theme_bw())
cbPalette <- c("#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73")
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
source("../../helpers.R")
```


```{r}
read.pcibex <- function(filepath, auto.colnames=TRUE, fun.col=function(col,cols){cols[cols==col]<-paste(col,"Ibex",sep=".");return(cols)}) {
  n.cols <- max(count.fields(filepath,sep=",",quote=NULL),na.rm=TRUE)
  if (auto.colnames){
    cols <- c()
    con <- file(filepath, "r")
    while ( TRUE ) {
      line <- readLines(con, n = 1, warn=FALSE)
      if ( length(line) == 0) {
        break
      }
      m <- regmatches(line,regexec("^# (\\d+)\\. (.+)\\.$",line))[[1]]
      if (length(m) == 3) {
        index <- as.numeric(m[2])
        value <- m[3]
        if (is.function(fun.col)){
         cols <- fun.col(value,cols)
        }
        cols[index] <- value
        if (index == n.cols){
          break
        }
      }
    }
    close(con)
    return(read.csv(filepath, comment.char="#", header=FALSE, col.names=cols))
  }
  else{
    return(read.csv(filepath, comment.char="#", header=FALSE, col.names=seq(1:n.cols)))
  }
}

# Read in the results
d <- read.pcibex("../data/results_prod.csv")

# facts <- read.csv("../data/adjs_list.csv")

names(d)
length(unique(d$ID))
length(unique(d$MD5.hash.of.participant.s.IP.address))
# length(unique(facts$Word))
```


```{r}

nrow(d)

d <- d %>% 
  filter((Label == "test"),
         (PennElementType %in% c("Scale"))) %>% 
   rename(ID.Ibex = MD5.hash.of.participant.s.IP.address,
          Response = Value)

nrow(d)

View(d)

length(unique(d$ID.Ibex))

# View(d)


d <- d[,c("ID.Ibex","Response","FeatureMatch","Word1","Word2")]



```

```{r}
write.csv(agr,"../data/norming_agg.csv")

# Write to .csv not aggregating over participants
write.csv(d,"../data/processed.csv")

```


# Take a look at comments and Problems
```{r}
unique(d$PennElementType)
comments <- d %>% filter((PennElementType == "TextInput") & (PennElementName == "Comments"))
unique(comments$Value)

comments <- d %>% filter((PennElementType == "TextInput") & (PennElementName == "Problems"))
unique(comments$Value)

comments <- d %>% filter((PennElementType == "TextInput") & (PennElementName == "NativeLang"))
unique(comments$Value)

comments <- d %>% filter((PennElementType == "TextInput") & (PennElementName == "OtherLangs"))

unique(comments$Value)

comments <- d %>% filter((PennElementType == "TextInput") & (PennElementName == "Gender"))
unique(comments$Value)
```



# training items to csv

```{r}


write.csv(d.train,"../data/processed_training.csv")

table(d.train$Task)

```
