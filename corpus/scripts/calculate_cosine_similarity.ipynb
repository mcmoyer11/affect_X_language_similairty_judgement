{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fe00d10-f0eb-46aa-b46d-96f8148ee0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/momo/opt/anaconda3/lib/python3.8/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import spacy\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load pre-trained word vectors (Google News Word2Vec format)\n",
    "# This will download ~1.5GB on first run\n",
    "import gensim.downloader as api\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47e73fb-076b-474f-9f6f-5530222fa79d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dbba3b8-7953-4555-89c7-8e4d9191587a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../exp_files/pilot.csv\")\n",
    "# a2 = pd.read_csv(\"../exp_files/total/exp-a2-pairs.csv\")\n",
    "# n = pd.read_csv(\"../exp_files/total/exp-n-pairs.csv\")\n",
    "# n2 = pd.read_csv(\"../exp_files/total/exp-n2-pairs.csv\")\n",
    "# s = pd.read_csv(\"../exp_files/total/exp-s-pairs.csv\")\n",
    "# v = pd.read_csv(\"../exp_files/total/exp-v-pairs.csv\")\n",
    "# v2 = pd.read_csv(\"../exp_files/total/exp-v2-pairs.csv\")\n",
    "# df = pd.concat([v,v2,n,n2,s,a,a2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a4dc1e-f7df-478f-9488-2ba65934e9bb",
   "metadata": {},
   "source": [
    "# Differences between Word2Vec and SentenceTransformer embeddings for similarity\n",
    "Aspect\tWord2Vec Google News (300d)\tSentenceTransformer all-MiniLM-L6-v2 (384d)\n",
    "Type of embedding\tWord-level embedding\tSentence / phrase embedding (can also be single words)\n",
    "Training data\tGoogle News corpus (~100 billion tokens)\tLarge-scale datasets with sentences and semantic labels (e.g. NLI, STS)\n",
    "Vector size\t300 dimensions\t384 dimensions\n",
    "Context\tStatic embeddings: Each word has one vector regardless of context\tContextual embeddings (fine-tuned for sentence similarity)\n",
    "Usage\tGood for general word similarity and analogy\tExcellent for sentence, phrase, and word similarity — captures semantics better\n",
    "Similarity measure\tCosine similarity on static vectors\tCosine similarity on context-aware vectors\n",
    "Out-of-vocabulary handling\tWords not in vocab get no vector\tCan embed any text string, including OOV words\n",
    "Performance\tFast, lightweight, easy to use\tSlightly heavier model, but more powerful and versatile\n",
    "Meaning captured\tWord co-occurrence patterns\tSemantic meaning in context, better for polysemy and phrase meaning\n",
    "\n",
    "In simpler terms:\n",
    "Word2Vec gives you a single fixed vector per word, learned from word co-occurrence statistics in a huge news corpus. It doesn’t consider context — the vector for “bank” is the same whether it’s a river bank or a financial bank.\n",
    "\n",
    "SentenceTransformer embeddings are generated by a transformer model trained on tasks that require understanding sentence meaning. Even a single word embedding reflects some context and semantic nuance. It works better for phrases, sentences, or words with multiple meanings.\n",
    "\n",
    "When to use which?\n",
    "Task\tRecommended model\n",
    "Simple word similarity or analogies\tWord2Vec Google News\n",
    "Sentence or phrase similarity\tSentenceTransformer (MiniLM or others)\n",
    "Handling ambiguous or out-of-vocab words\tSentenceTransformer\n",
    "Downstream NLP tasks requiring semantic understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfd2c2e-9198-4a5f-8c59-25d42ff8e2d9",
   "metadata": {},
   "source": [
    "# Get similarity with word-2-vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62b4cdbf-3192-42bb-83e4-044dd089c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model1 = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcf1f31e-bb91-4e0b-bd64-1bf41e19b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(w1, w2):\n",
    "    if w1 in model1 and w2 in model1:\n",
    "        return model1.similarity(w1, w2)\n",
    "    else:\n",
    "        return None  # or 0, or np.nan\n",
    "df[\"W2VSimilarity\"] = df.apply(lambda row: get_similarity(row[\"Word1\"], row[\"Word2\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4156a71-1d4e-43f4-abd7-16cb08df0d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dc92ed7-1d3c-4178-9757-7358f7291aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Word1</th>\n",
       "      <th>Word2</th>\n",
       "      <th>FeatureCombo1</th>\n",
       "      <th>FeatureCombo2</th>\n",
       "      <th>FeatureMatch</th>\n",
       "      <th>W2VSimilarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "      <td>clean</td>\n",
       "      <td>burn</td>\n",
       "      <td>physical-positive</td>\n",
       "      <td>physical-negative</td>\n",
       "      <td>ConceptualMatchingOnly</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>caress</td>\n",
       "      <td>rust</td>\n",
       "      <td>physical-positive</td>\n",
       "      <td>physical-negative</td>\n",
       "      <td>ConceptualMatchingOnly</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>158</td>\n",
       "      <td>reassure</td>\n",
       "      <td>criticize</td>\n",
       "      <td>psychological-positive</td>\n",
       "      <td>psychological-negative</td>\n",
       "      <td>ConceptualMatchingOnly</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115</td>\n",
       "      <td>encourage</td>\n",
       "      <td>embarrass</td>\n",
       "      <td>psychological-positive</td>\n",
       "      <td>psychological-negative</td>\n",
       "      <td>ConceptualMatchingOnly</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69</td>\n",
       "      <td>sculpt</td>\n",
       "      <td>corrode</td>\n",
       "      <td>physical-positive</td>\n",
       "      <td>physical-negative</td>\n",
       "      <td>ConceptualMatchingOnly</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Word1      Word2           FeatureCombo1  \\\n",
       "0          95      clean       burn       physical-positive   \n",
       "1          30     caress       rust       physical-positive   \n",
       "2         158   reassure  criticize  psychological-positive   \n",
       "3         115  encourage  embarrass  psychological-positive   \n",
       "4          69     sculpt    corrode       physical-positive   \n",
       "\n",
       "            FeatureCombo2            FeatureMatch W2VSimilarity  \n",
       "0       physical-negative  ConceptualMatchingOnly          None  \n",
       "1       physical-negative  ConceptualMatchingOnly          None  \n",
       "2  psychological-negative  ConceptualMatchingOnly          None  \n",
       "3  psychological-negative  ConceptualMatchingOnly          None  \n",
       "4       physical-negative  ConceptualMatchingOnly          None  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ccf58a-b085-4720-b2d1-635732fc5102",
   "metadata": {},
   "source": [
    "# Try with transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e483383-1264-43b0-9337-ab71810585ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model2 = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8015185-3418-44db-b7d1-c636c7f56417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarities\n",
    "def get_similarity(w1, w2):\n",
    "    v1 = model2.encode(w1)\n",
    "    v2 = model2.encode(w2)\n",
    "    return cosine_similarity([v1], [v2])[0][0]\n",
    "\n",
    "df[\"CosineSimilarity\"] = df.apply(lambda row: get_similarity(row[\"Word1\"], row[\"Word2\"]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc5c2832-e19d-4c27-9259-67d3da378e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Word1</th>\n",
       "      <th>Word2</th>\n",
       "      <th>FeatureCombo1</th>\n",
       "      <th>FeatureCombo2</th>\n",
       "      <th>FeatureMatch</th>\n",
       "      <th>W2VSimilarity</th>\n",
       "      <th>CosineSimilarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "      <td>clean</td>\n",
       "      <td>burn</td>\n",
       "      <td>physical-positive</td>\n",
       "      <td>physical-negative</td>\n",
       "      <td>ConceptualMatchingOnly</td>\n",
       "      <td>0.223062</td>\n",
       "      <td>0.407466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>caress</td>\n",
       "      <td>rust</td>\n",
       "      <td>physical-positive</td>\n",
       "      <td>physical-negative</td>\n",
       "      <td>ConceptualMatchingOnly</td>\n",
       "      <td>0.125289</td>\n",
       "      <td>0.232726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>158</td>\n",
       "      <td>reassure</td>\n",
       "      <td>criticize</td>\n",
       "      <td>psychological-positive</td>\n",
       "      <td>psychological-negative</td>\n",
       "      <td>ConceptualMatchingOnly</td>\n",
       "      <td>0.267650</td>\n",
       "      <td>0.317731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115</td>\n",
       "      <td>encourage</td>\n",
       "      <td>embarrass</td>\n",
       "      <td>psychological-positive</td>\n",
       "      <td>psychological-negative</td>\n",
       "      <td>ConceptualMatchingOnly</td>\n",
       "      <td>0.298619</td>\n",
       "      <td>0.245418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69</td>\n",
       "      <td>sculpt</td>\n",
       "      <td>corrode</td>\n",
       "      <td>physical-positive</td>\n",
       "      <td>physical-negative</td>\n",
       "      <td>ConceptualMatchingOnly</td>\n",
       "      <td>0.178691</td>\n",
       "      <td>0.186632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Word1      Word2           FeatureCombo1  \\\n",
       "0          95      clean       burn       physical-positive   \n",
       "1          30     caress       rust       physical-positive   \n",
       "2         158   reassure  criticize  psychological-positive   \n",
       "3         115  encourage  embarrass  psychological-positive   \n",
       "4          69     sculpt    corrode       physical-positive   \n",
       "\n",
       "            FeatureCombo2            FeatureMatch  W2VSimilarity  \\\n",
       "0       physical-negative  ConceptualMatchingOnly       0.223062   \n",
       "1       physical-negative  ConceptualMatchingOnly       0.125289   \n",
       "2  psychological-negative  ConceptualMatchingOnly       0.267650   \n",
       "3  psychological-negative  ConceptualMatchingOnly       0.298619   \n",
       "4       physical-negative  ConceptualMatchingOnly       0.178691   \n",
       "\n",
       "   CosineSimilarity  \n",
       "0          0.407466  \n",
       "1          0.232726  \n",
       "2          0.317731  \n",
       "3          0.245418  \n",
       "4          0.186632  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37c8e209-6607-4c2b-bc2e-715feac3d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../exp_files/pilot_similarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1bf30-8b71-4d0d-8dae-b094c3bf4a06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
